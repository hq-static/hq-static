### 3-2-1 用户行为数据处理过程

### 本周作业

- 选取一个程序功能（课堂未分析），分析程序代码（按照代码执行顺序写）

- 分析当前数据在大数据组件下的处理流程

#### 整体流程

日志log --> hadoop（hdfs --> yarn）--> hbase-> hive --> java app

![](img\3-2-1.png)

#### 数据导入

##### 系统准备

3个节点

​	hadoop：1主，2从

​	HBase：1主，2从

​	Hive：1主

- 启动mysql：service mysqld start
- 同步时间：sudo ntpdate pool.ntp.org

##### 大数据组件启动

- 启动zookeeper：runRemoteCmd.sh "/home/hadoop/app/zookeeper/bin/zkServer.sh status" all
- 启动hadoop：sbin/start-dfs.sh
- 启动yarn：sbin/start-yarn.sh
  - sbin/yarn-daemon.sh start resourcemanager
- 启动hive：
  - bin/hive --service metastore
  - bin/hive --service hiveserver2

##### 导入用户行为日志

- 启动beeline：bin/beeline
- 连接hive：!connect jdbc:hive2://hadoop03:10000
- 创建表：CREATE external TABLE sogoulogs(logtime string,uid STRING,keywords string,resultno string,clickno string,url string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
- 上传数据：bin/hdfs dfs -put {文件路径} /test
  - 若无权限，需设置权限bin/hdfs dfs -chmod -R 777 /test
- 导入文件：load data inpath ‘{hdfs中的文件路径}’ into table sogoulogs;

#### 配置参数讲解

#### zookeeper配置

/home/hadoop/app/zookeeper/conf/zoo.cfg

```
...
dataDir=/home/hadoop/data/zookeeper/zkdata

dataLogDir=/home/hadoop/data/zookeeper/zkdatalog
...
server.1=hadoop01:2888:3888
server.2=hadoop02:2888:3888
server.3=hadoop03:2888:3888
```

数据目录（/home/hadoop/data/zookeeper/zkdata）下创建myid文件

#### hadoop配置

etc/hadoop/hadoop-env.sh

```
export JAVA_HOME=/home/hadoop/app/jdk
export HADOOP_HOME=/home/hadoop/app/hadoop
```

core-site.xml

```
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://mycluster</value>
        </property>
        <!--默认的HDFS路径-->
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/home/hadoop/data/tmp</value>
        </property>
        <!--hadoop的临时目录，如果需要配置多个目录，需要逗号隔开-->
        <property>
        <name>ha.zookeeper.quorum</name>
        <value>hadoop01:2181,hadoop02:2181,hadoop03:2181</value>
        </property>
        <!--配置Zookeeper 管理HDFS-->
        <property>
                <name>hadoop.proxyuser.hadoop.hosts</name>
                <value>*</value>
        </property>
        <property>
                <name>hadoop.proxyuser.hadoop.groups</name>
                <value>*</value>
        </property>
```

hdfs-site.xml（主要是修改主机名）

https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml

```
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
                <!--数据块副本数为3-->
        <property>
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
        <property>
                <name>dfs.permissions.enabled</name>
                <value>false</value>
        </property>
                <!--权限默认配置为false-->
        <property>
                <name>dfs.nameservices</name>
                <value>mycluster</value>
        </property>
                <!--命名空间，它的值与fs.defaultFS的值要对应，namenode高可用之后有两个namenode，mycluster是对外提供的统一入口-->
        <property>
                <name>dfs.ha.namenodes.mycluster</name>
                <value>nn1,nn2</value>
        </property>
                <!-- 指定 nameService 是 mycluster时的nameNode有哪些，这里的值也是逻辑名称，名字随便起，相互不重复即可-->
        <property>
                <name>dfs.namenode.rpc-address.mycluster.nn1</name>
                <value>hadoop01:9000</value>
        </property>
        <property>
                <name>dfs.namenode.http-address.mycluster.nn1</name>
                <value>hadoop01:50070</value>
        </property>
        <property>
                <name>dfs.namenode.rpc-address.mycluster.nn2</name>
                <value>hadoop02:9000</value>
        </property>
        <property>
                <name>dfs.namenode.http-address.mycluster.nn2</name>
                <value>hadoop02:50070</value>
        </property>
        <property>
                <name>dfs.ha.automatic-failover.enabled</name>
                <value>true</value>
        </property>
                <!--启动故障自动恢复-->
        <property>
                <name>dfs.namenode.shared.edits.dir</name>
                <value>qjournal://hadoop01:8485;hadoop02:8485;hadoop03:8485/mycluster</value>
        </property>
                <!--指定NameNode的元数据在JournalNode上的存放位置-->
        <property>
                <name>dfs.client.failover.proxy.provider.mycluster</name>
                <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        </property>
                <!--指定 mycluster 出故障时，哪个实现类负责执行故障切换-->
        <property>
                <name>dfs.journalnode.edits.dir</name>
                <value>/home/hadoop/data/journaldata/jn</value>
        </property>
                <!-- 指定JournalNode在本地磁盘存放数据的位置 -->
        <property>
                <name>dfs.ha.fencing.methods</name>
                <value>shell(/bin/true)</value>
        </property>
                <!-- 配置隔离机制,shell通过ssh连接active namenode节点，杀掉进程-->
        <property>
                <name>dfs.ha.fencing.ssh.private-key-files</name>
                <value>/home/hadoop/.ssh/id_rsa</value>
        </property>
                <!-- 为了实现SSH登录杀掉进程，还需要配置免密码登录的SSH密匙信息 -->
        <property>
                <name>dfs.ha.fencing.ssh.connect-timeout</name>
                <value>10000</value>
        </property>
        <property>
                <name>dfs.namenode.handler.count</name>
                <value>100</value>
        </property>
</configuration>
```

slaves（声明集群节点）

```
hadoop01
hadoop02
hadoop03
```

#### HBase配置

- hbase-site.xml

https://hbase.apache.org/book.html#config.files

```
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
                <!--数据块副本数为3-->
        <property>
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
        <property>
                <name>dfs.permissions.enabled</name>
                <value>false</value>
        </property>
                <!--权限默认配置为false-->
        <property>
                <name>dfs.nameservices</name>
                <value>mycluster</value>
        </property>
                <!--命名空间，它的值与fs.defaultFS的值要对应，namenode高可用之后有两个namenode，mycluster是对外提供的统一入口-->
        <property>
                <name>dfs.ha.namenodes.mycluster</name>
                <value>nn1,nn2</value>
        </property>
                <!-- 指定 nameService 是 mycluster时的nameNode有哪些，这里的值也是逻辑名称，名字随便起，相互不重复即可-->
        <property>
                <name>dfs.namenode.rpc-address.mycluster.nn1</name>
                <value>hadoop01:9000</value>
        </property>
        <property>
                <name>dfs.namenode.http-address.mycluster.nn1</name>
                <value>hadoop01:50070</value>
        </property>
        <property>
                <name>dfs.namenode.rpc-address.mycluster.nn2</name>
                <value>hadoop02:9000</value>
        </property>
        <property>
                <name>dfs.namenode.http-address.mycluster.nn2</name>
                <value>hadoop02:50070</value>
        </property>
        <property>
                <name>dfs.ha.automatic-failover.enabled</name>
                <value>true</value>
        </property>
                <!--启动故障自动恢复-->
        <property>
                <name>dfs.namenode.shared.edits.dir</name>
                <value>qjournal://hadoop01:8485;hadoop02:8485;hadoop03:8485/mycluster</value>
        </property>
                <!--指定NameNode的元数据在JournalNode上的存放位置-->
        <property>
                <name>dfs.client.failover.proxy.provider.mycluster</name>
                <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        </property>
                <!--指定 mycluster 出故障时，哪个实现类负责执行故障切换-->
        <property>
                <name>dfs.journalnode.edits.dir</name>
                <value>/home/hadoop/data/journaldata/jn</value>
        </property>
                <!-- 指定JournalNode在本地磁盘存放数据的位置 -->
        <property>
                <name>dfs.ha.fencing.methods</name>
                <value>shell(/bin/true)</value>
        </property>
                <!-- 配置隔离机制,shell通过ssh连接active namenode节点，杀掉进程-->
        <property>
                <name>dfs.ha.fencing.ssh.private-key-files</name>
                <value>/home/hadoop/.ssh/id_rsa</value>
        </property>
                <!-- 为了实现SSH登录杀掉进程，还需要配置免密码登录的SSH密匙信息 -->
        <property>
                <name>dfs.ha.fencing.ssh.connect-timeout</name>
                <value>10000</value>
        </property>
        <property>
                <name>dfs.namenode.handler.count</name>
                <value>100</value>
        </property>
</configuration>
```

- regionservers

```
hadoop01
hadoop02
hadoop03
```

- backup-masters
- hbase-env.sh

```
export JAVA_HOME=
export HBASE_LOG_DIR=
export HBASE_PID_DIR=
```

- core-site.xml（从hadoop中获取）
- hdfs-site.xml（从hadoop中获取）
- 设置环境变量（.bashrc)
  - source生效


#### hive配置

##### mysql配置

- 创建hive用户及授权

```
create user 'hive' identified by 'hive';`
grant all on *.*to 'hive'@'hadoop03' identified by 'hive';`
flush privileges;`
```

- 创建hive库

```
mysql -u hive -h hadoop03 -p
create database metastore;
```

##### hive配置

- hive-log4j.properties：配置hive.log.dir
- hive-env.sh（输出HADOOP_HOME、HIVE_CONF_DIR、HBASE_HOME）
- hive-site.xml（略）：从hive-default.xml.template拷贝而来

##### 上传mysql驱动

```
mv mysql-connector-java-5.1.38.jar hive/lib/
```

 